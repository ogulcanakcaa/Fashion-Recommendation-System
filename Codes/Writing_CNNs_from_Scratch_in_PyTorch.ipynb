{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "from IPython.core.display import HTML "
      ],
      "metadata": {
        "id": "Oq1djfORfL9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "One of the best ways to learn about convolutional neural networks (CNNs) is to write one from scratch! In this post we look to use PyTorch and the CIFAR-10 dataset to create a new neural network."
      ],
      "metadata": {
        "id": "FD07Bu3RcgPy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Introduction\n",
        "\n",
        "In this article, we will be building Convolutional Neural Networks (CNNs) from scratch in PyTorch, and seeing them in action as we train and test them on a real-world dataset.\n",
        "\n",
        "We will start by exploring what CNNs are and how they work. We will then look into PyTorch and start by loading the CIFAR10 dataset using torchvision (a library containing various datasets and helper functions related to computer vision). We will then build and train our CNN from scratch. Finally, we will test our model.\n",
        "\n",
        "Below is the outline of the article:\n",
        "\n",
        "* Introduction\n",
        "* Convolutional Neural Networks\n",
        "* PyTorch\n",
        "* Data Loading\n",
        "* CNN from Scratch\n",
        "* Setting Hyperparameters\n",
        "* Training\n",
        "* Testing"
      ],
      "metadata": {
        "id": "t1OMMoA6cyBf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Convolutional Neural Networks"
      ],
      "metadata": {
        "id": "DWOFPdu9exBp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A convolutional neural network (CNN) takes an input image and classifies it into any of the output classes. Each image passes through a series of different layers – primarily convolutional layers, pooling layers, and fully connected layers. The below picture summarizes what an image passes through in a CNN:\n"
      ],
      "metadata": {
        "id": "3YhrEXP_e1HG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<img src = \"https://blog.paperspace.com/content/images/size/w1000/2021/05/image-32.png\" width=1000 height=338>"
      ],
      "metadata": {
        "id": "eEJ1Jh2ji-o7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Convolutional Layer"
      ],
      "metadata": {
        "id": "SOU99XZSgNlD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The convolutional layer is used to extract features from the input image. It is a mathematical operation between the input image and the kernel (filter). The filter is passed through the image and the output is calculated as follows:"
      ],
      "metadata": {
        "id": "5aboxxNmgSmU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<img src = \"https://blog.paperspace.com/content/images/size/w1000/2021/08/Convolutional.webp\" width=1000 height=582>"
      ],
      "metadata": {
        "id": "tmmnmciIiyQ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Different filters are used to extract different kinds of features. Some common features are given below:"
      ],
      "metadata": {
        "id": "QAwGBNdRhFot"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<img src = \"https://blog.paperspace.com/content/images/2021/05/image-34.png\" width=349 height=564>"
      ],
      "metadata": {
        "id": "4ABHdeY2ip8i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pooling Layers"
      ],
      "metadata": {
        "id": "N8_7vhAUhiLc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pooling layers are used to reduce the size of any image while maintaining the most important features. The most common types of pooling layers used are max and average pooling which take the max and the average value respectively from the given size of the filter (i.e, 2x2, 3x3, and so on).\n",
        "\n",
        "Max pooling, for example, would work as follows:"
      ],
      "metadata": {
        "id": "-7YLgiR8hlNz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<img src = \"https://blog.paperspace.com/content/images/2021/05/image-35.png\" width=602 height=287>"
      ],
      "metadata": {
        "id": "2Xb4omy5in2J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pytorch\n"
      ],
      "metadata": {
        "id": "hkjw7wmrjI-3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch is one of the most popular and widely used deep learning libraries – especially within academic research. It's an open-source machine learning framework that accelerates the path from research prototyping to production deployment and we'll be using it today in this article to create our first CNN.\n",
        "\n",
        "#Data Loading\n",
        "##Dataset\n",
        "Let's start by loading some data. We will be using the CIFAR-10 dataset. The dataset has 60,000 color images (RGB) at 32px x 32px belonging to 10 different classes (6000 images/class). The dataset is divided into 50,000 training and 10,000 testing images.\n",
        "\n",
        "You can see a sample of the dataset along with their classes below:"
      ],
      "metadata": {
        "id": "thfkL0_AjNIC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<img src = \"https://blog.paperspace.com/content/images/2021/07/Screen-Shot-2021-07-02-at-4.37.09-PM.png\" width=930 height=706>"
      ],
      "metadata": {
        "id": "F3LIOcbWj0cA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importing the Libraries\n",
        "Let's start by importing the required libraries and defining some variables:"
      ],
      "metadata": {
        "id": "yGfNCNn7j5GW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in relevant libraries, and alias where appropriate\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Define relevant variables for the ML task\n",
        "batch_size = 64\n",
        "num_classes = 10\n",
        "learning_rate = 0.001\n",
        "num_epochs = 20\n",
        "\n",
        "# Device will determine whether to run the training on GPU or CPU.\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "ChVdVZ9Ij0r4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dataset Loading"
      ],
      "metadata": {
        "id": "uNM8wFGukYt2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To load the dataset, we will be using the built-in datasets in torchvision. It provides us with the ability to download the dataset and also apply any transformations we want.\n",
        "\n",
        "Let's look at the code first:"
      ],
      "metadata": {
        "id": "iREN1I95kbJO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use transforms.compose method to reformat images for modeling,\n",
        "# and save to variable all_transforms for later use\n",
        "all_transforms = transforms.Compose([transforms.Resize((32,32)),\n",
        "                                     transforms.ToTensor(),\n",
        "                                     transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
        "                                                          std=[0.2023, 0.1994, 0.2010])\n",
        "                                     ])\n",
        "# Create Training dataset\n",
        "train_dataset = torchvision.datasets.CIFAR10(root = './data',\n",
        "                                             train = True,\n",
        "                                             transform = all_transforms,\n",
        "                                             download = True)\n",
        "\n",
        "# Create Testing dataset\n",
        "test_dataset = torchvision.datasets.CIFAR10(root = './data',\n",
        "                                            train = False,\n",
        "                                            transform = all_transforms,\n",
        "                                            download=True)\n",
        "\n",
        "# Instantiate loader objects to facilitate processing\n",
        "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
        "                                           batch_size = batch_size,\n",
        "                                           shuffle = True)\n",
        "\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
        "                                           batch_size = batch_size,\n",
        "                                           shuffle = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Z-0HBSej781",
        "outputId": "c4fbdb93-ebdb-4f10-856b-34ee585798f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:04<00:00, 36628712.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's dissect this piece of code:\n",
        "\n",
        "* We start by writing some transformations. We resize the images, convert them to tensors and normalize them by using the mean and standard deviation of each band in the input images. You can calculate these as well, but they are available online.\n",
        "* Then, we load the dataset: both training and testing. We set download equal to True so that it is downloaded if not already downloaded.\n",
        "* Loading the whole dataset into the RAM at once is not a good practice and can seriously halt your computer. That's why we use data loaders, which allow you to iterate through the dataset by loading the data in batches.\n",
        "* We then create two data loaders (for train/test) and set the batch size, along with shuffle, equal to True, so that images from each class are included in a batch."
      ],
      "metadata": {
        "id": "xVPiglqOkknm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CNN from Scratch\n",
        "Before diving into the code, let's explain how you define a neural network in PyTorch.\n",
        "\n",
        "* You start by creating a new class that extends the nn.Module class from PyTorch. This is needed when we are creating a neural network as it provides us with a bunch of useful methods\n",
        "* We then have to define the layers in our neural network. This is done in the __init__ method of the class. We simply name our layers, and then assign them to the appropriate layer that we want; e.g., convolutional layer, pooling layer, fully connected layer, etc.\n",
        "* The final thing to do is define a forward method in our class. The purpose of this method is to define the order in which the input data passes through the various layers\n",
        "Now, let's dive into the code:"
      ],
      "metadata": {
        "id": "zT1oRYTWksqG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a CNN class\n",
        "class ConvNeuralNet(nn.Module):\n",
        "\t#  Determine what layers and their order in CNN object \n",
        "    def __init__(self, num_classes):\n",
        "        super(ConvNeuralNet, self).__init__()\n",
        "        self.conv_layer1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3)\n",
        "        self.conv_layer2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3)\n",
        "        self.max_pool1 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "        \n",
        "        self.conv_layer3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n",
        "        self.conv_layer4 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3)\n",
        "        self.max_pool2 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "        \n",
        "        self.fc1 = nn.Linear(1600, 128)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "    \n",
        "    # Progresses data across layers    \n",
        "    def forward(self, x):\n",
        "        out = self.conv_layer1(x)\n",
        "        out = self.conv_layer2(out)\n",
        "        out = self.max_pool1(out)\n",
        "        \n",
        "        out = self.conv_layer3(out)\n",
        "        out = self.conv_layer4(out)\n",
        "        out = self.max_pool2(out)\n",
        "                \n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        \n",
        "        out = self.fc1(out)\n",
        "        out = self.relu1(out)\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "W3IkPzZtkpRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As I explained above, we start by creating a class that inherits the nn.Module class, and then we define the layers and their sequence of execution inside __init__ and forward respectively.\n",
        "\n",
        "Some things to notice here:\n",
        "\n",
        "* nn.Conv2d is used to define the convolutional layers. We define the channels they receive and how much should they return along with the kernel size. We start from 3 channels, as we are using RGB images\n",
        "* nn.MaxPool2d is a max-pooling layer that just requires the kernel size and the stride\n",
        "* nn.Linear is the fully connected layer, and nn.ReLU is the activation function used\n",
        "* In the forward method, we define the sequence, and, before the fully connected layers, we reshape the output to match the input to a fully connected layer"
      ],
      "metadata": {
        "id": "nfphzkb7lCU5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Setting Hyperparameters"
      ],
      "metadata": {
        "id": "sQq0OCgClN2m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = ConvNeuralNet(num_classes)\n",
        "\n",
        "# Set Loss function with criterion\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Set optimizer with optimizer\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay = 0.005, momentum = 0.9)  \n",
        "\n",
        "total_step = len(train_loader)"
      ],
      "metadata": {
        "id": "l4LMdl35lAFH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We start by initializing our model with the number of classes. We then choose cross-entropy and SGD (Stochastic Gradient Descent) as our loss function and optimizer respectively. There are different choices for these, but I found these to result in maximum accuracy when experimenting. We also define the variable total_step to make iteration through various batches easier."
      ],
      "metadata": {
        "id": "tQsw2Oi4lq9s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training\n",
        "Now, let's start training our model:"
      ],
      "metadata": {
        "id": "dti8O9jylu6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We use the pre-defined number of epochs to determine how many iterations to train the network on\n",
        "for epoch in range(num_epochs):\n",
        "\t#Load in the data in batches using the train_loader object\n",
        "    for i, (images, labels) in enumerate(train_loader):  \n",
        "        # Move tensors to the configured device\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))\n",
        "\n",
        "            \n",
        "            \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yM9DLRmelvKn",
        "outputId": "3d7e9179-1655-4f48-8398-166feec4c100"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/20], Loss: 2.0229\n",
            "Epoch [2/20], Loss: 1.1552\n",
            "Epoch [3/20], Loss: 1.2464\n",
            "Epoch [4/20], Loss: 1.0745\n",
            "Epoch [5/20], Loss: 1.6057\n",
            "Epoch [6/20], Loss: 1.3674\n",
            "Epoch [7/20], Loss: 0.8286\n",
            "Epoch [8/20], Loss: 0.8284\n",
            "Epoch [9/20], Loss: 0.9497\n",
            "Epoch [10/20], Loss: 1.0507\n",
            "Epoch [11/20], Loss: 0.5861\n",
            "Epoch [12/20], Loss: 0.3720\n",
            "Epoch [13/20], Loss: 1.6261\n",
            "Epoch [14/20], Loss: 1.2345\n",
            "Epoch [15/20], Loss: 0.8486\n",
            "Epoch [16/20], Loss: 0.7890\n",
            "Epoch [17/20], Loss: 0.5642\n",
            "Epoch [18/20], Loss: 0.4738\n",
            "Epoch [19/20], Loss: 0.4679\n",
            "Epoch [20/20], Loss: 0.4087\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is probably the trickiest part of the code. Let's see what the code does:\n",
        "\n",
        "* We start by iterating through the number of epochs, and then the batches in our training data\n",
        "* We convert the images and the labels according to the device we are using, i.e., GPU or CPU\n",
        "* In the forward pass we make predictions using our model and calculate loss based on those predictions and our actual labels\n",
        "* Next, we do the backward pass where we actually update our weights to improve our model\n",
        "* We then set the gradients to zero before every update using optimizer.zero_grad() function\n",
        "* Then, we calculate the new gradients using the loss.backward() function\n",
        "* And finally, we update the weights with the optimizer.step() function\n",
        "We can see the output as follows:"
      ],
      "metadata": {
        "id": "wpCiZS9_l3Sy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<img src = \"https://blog.paperspace.com/content/images/2021/07/Screen-Shot-2021-07-11-at-5.22.34-AM.png\" width=416 height=480>"
      ],
      "metadata": {
        "id": "p2olrselmWXk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, the loss is slightly decreasing with more and more epochs. This is a good sign. But you may notice that it is fluctuating at the end, which could mean the model is overfitting or that the batch_size is small. We will have to test to find out what's going on."
      ],
      "metadata": {
        "id": "QW9h-1O0mZvT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Testing\n",
        "Let's now test our model. The code for testing is not so different from training, with the exception of calculating the gradients as we are not updating any weights:"
      ],
      "metadata": {
        "id": "aYQIZ3fRmcP_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    \n",
        "    print('Accuracy of the network on the {} train images: {} %'.format(50000, 100 * correct / total))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "r2kstgU7maAb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca497d04-55a7-4bbb-d578-fb20406f8ba5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 50000 train images: 83.392 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We wrap the code inside torch.no_grad() as there is no need to calculate any gradients. We then predict each batch using our model and calculate how many it predicts correctly. We get the final result of ~83% accuracy:"
      ],
      "metadata": {
        "id": "-d6l59aWmpyX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<img src = \"https://blog.paperspace.com/content/images/2021/07/Screen-Shot-2021-07-11-at-5.28.11-AM.png\" width=824 height=40>"
      ],
      "metadata": {
        "id": "mEnr-6mKnurS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "And that's it. We managed to create a Convolutional Neural Network from scratch in PyTorch!\n",
        "\n",
        "# Conclusion\n",
        "We started by learning about CNNs – what kind of layers they have and how they work. We then introduced PyTorch, which is one of the most popular deep learning libraries available today. We learned how PyTorch would make it much easier for us to experiment with a CNN."
      ],
      "metadata": {
        "id": "2-cQ_cUMoFTG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C4P01yWzoLJf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}